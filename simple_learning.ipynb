{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "genetic-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from random import random\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-nickname",
   "metadata": {},
   "source": [
    "# データのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "emerging-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = Path.cwd()\n",
    "path_train_csv = WORK_DIR/\"train.csv/\"\n",
    "train_csv = pd.read_csv(path_train_csv)\n",
    "path_train_img = WORK_DIR/\"train_images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-cooking",
   "metadata": {},
   "source": [
    "# データのペアの作成\n",
    "二つの画像が同じ商品かを判定するための画像のペアを作成する。<br>\n",
    "match_rateの比率に基づいて一致する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "auburn-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_rate = 0.3\n",
    "paired_num_list = []\n",
    "match_or_not_list = []\n",
    "train_csv_paired = train_csv.copy()\n",
    "for i in range(len(train_csv)):\n",
    "    df = train_csv.iloc[i]\n",
    "    posting_id = df.posting_id\n",
    "    label_group = df.label_group\n",
    "    if random() < match_rate:\n",
    "        #同じlabel_groupの画像同士を用いる\n",
    "        df_samelabel = train_csv[(train_csv.label_group == label_group)\n",
    "                                 &\n",
    "                                 (train_csv.posting_id != posting_id)]\n",
    "        df2 = df_samelabel.sample().copy()\n",
    "        is_match = 1\n",
    "    else:\n",
    "        #異なるlabel_groupの画像同士を用いる\n",
    "        df2 =  train_csv[train_csv.index != posting_id].sample().copy()\n",
    "        is_match = 0\n",
    "    paired_num_list.append(df2.index[0]) #ペアにした画像のindexを加える\n",
    "    match_or_not_list.append(is_match) #ペアの画像のlabel_groupがマッチするかを加える\n",
    "train_csv_paired.loc[:,[\"paired_num\"]] = paired_num_list\n",
    "train_csv_paired.loc[:,[\"match_or_not\"]] = match_or_not_list "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-database",
   "metadata": {},
   "source": [
    "# Dataset, Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "confident-trailer",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#==Dataset==\n",
    "class Mydatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, dir_image, input_size, transform = None):\n",
    "        self.transform = transform\n",
    "        self.df = df\n",
    "        self.dir_image = dir_image \n",
    "        self.input_size = input_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #画像を2枚と、その2枚の画像のlbael_groupが一致(1)か不一致(0)かを出力する。\n",
    "        #一枚目の画像はidxで指定し、2枚目はランダムで指定\n",
    "        df = self.df.iloc[idx]\n",
    "        imagename = df.image \n",
    "        path_image = self.dir_image/imagename\n",
    "        image = Image.open(path_image)\n",
    "        image = image.resize(self.input_size)\n",
    "        image = torchvision.transforms.functional.to_tensor(image)\n",
    "        \n",
    "        paired_num = df.paired_num\n",
    "        df2 = self.df.iloc[paired_num]\n",
    "        imagename2 = df2.image\n",
    "        path_image2 = self.dir_image/imagename2\n",
    "        image2 = Image.open(path_image2)\n",
    "        image2 = image2.resize(self.input_size)\n",
    "        image2 = torchvision.transforms.functional.to_tensor(image2)\n",
    "        \n",
    "        match_or_not = torch.tensor(df.match_or_not)\n",
    "            \n",
    "        return image,image2,match_or_not\n",
    "    \n",
    "    \n",
    "#==Dataloader==\n",
    "train_dataset = Mydatasets(train_csv_paired,WORK_DIR/\"train_images/\",(224,224))\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=16, shuffle=True,\n",
    "    #num_workers=2, \n",
    "    drop_last=True)\n",
    "\n",
    "images, images2, labels = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-presentation",
   "metadata": {},
   "source": [
    "# モデル "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "young-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "res = models.resnet18(pretrained=True)\n",
    "# すべてのパラメータを固定\n",
    "for param in res.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "computational-dependence",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.fc1_1 = torch.nn.Linear(1000, 300)\n",
    "            self.fc1_2 = torch.nn.Linear(300, 50)\n",
    "            self.fc2_1 = torch.nn.Linear(1000, 300)\n",
    "            self.fc2_2 = torch.nn.Linear(300, 50)\n",
    "            self.fc3_1 = torch.nn.Linear(100,50)\n",
    "            self.fc3_2 = torch.nn.Linear(50,2)\n",
    "        def forward(self,x1,x2):\n",
    "            x1 = res(x1)\n",
    "            x1 = self.fc1_1(x1)\n",
    "            x1 = torch.sigmoid(x1)\n",
    "            x1 = self.fc1_2(x1)\n",
    "            \n",
    "            x2 = res(x2)\n",
    "            x2 = self.fc2_1(x2)\n",
    "            x2 = torch.sigmoid(x2)\n",
    "            x2 = self.fc2_2(x2)\n",
    "            \n",
    "            x = torch.cat([x1, x2], axis=1)\n",
    "            x = self.fc3_1(x)\n",
    "            x = self.fc3_2(x)\n",
    "            \n",
    "            return f.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-ferry",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "stainless-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "threaded-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "# 学習結果の保存用\n",
    "history = {\n",
    "        'train_loss': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc': [],\n",
    "    }\n",
    "optimizer = torch.optim.Adam(params=net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-explorer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bf1fed6d064a0eaab678e4c0d219ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c3c01608364b119a7bcbba56c6c8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07ae5a16e2b4bfda5dbb80ef1f2dd69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd2ffe656bc48a4871d1c72ed0db3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad8534ff5f04b8391789c8e5a91db93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f6507533d14a74b667e5575e6b0acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c06de7114774215a6f508862d9b35b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "for e in tqdm(range(epoch)):\n",
    "    loss = None\n",
    "\n",
    "    model.train(True)\n",
    "    \n",
    "    for i, (image,image2,label_group) in tqdm(enumerate(train_dataloader)):\n",
    "        outputs = model(image,image2)\n",
    "        loss = criterion(outputs, label_group)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # 学習のストップ\n",
    "    net.eval()  # または net.train(False) でも良い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
